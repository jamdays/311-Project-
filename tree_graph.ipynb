{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\oscar\\documents\\311-project-\\.venv\\lib\\site-packages (2.2.3)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.6.1-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Collecting graphviz\n",
      "  Using cached graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\oscar\\documents\\311-project-\\.venv\\lib\\site-packages (from pandas) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\oscar\\documents\\311-project-\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\oscar\\documents\\311-project-\\.venv\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\oscar\\documents\\311-project-\\.venv\\lib\\site-packages (from pandas) (2025.1)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Using cached scipy-1.15.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\oscar\\documents\\311-project-\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached scikit_learn-1.6.1-cp312-cp312-win_amd64.whl (11.1 MB)\n",
      "Using cached graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached scipy-1.15.2-cp312-cp312-win_amd64.whl (40.9 MB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, graphviz, scikit-learn\n",
      "Successfully installed graphviz-0.20.3 joblib-1.4.2 scikit-learn-1.6.1 scipy-1.15.2 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas scikit-learn graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mscripts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clean_data\n\u001b[32m      2\u001b[39m get_ipython().run_line_magic(\u001b[33m'\u001b[39m\u001b[33mpip\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33minstall pandas scikit-learn graphviz\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtree\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DecisionTreeClassifier\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\oscar\\Documents\\311-Project-\\scripts.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m __all__ = [\u001b[33m'\u001b[39m\u001b[33mclean_data\u001b[39m\u001b[33m'\u001b[39m]\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "from scripts import clean_data\n",
    "%pip install pandas scikit-learn graphviz\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from graphviz import Source\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild_all_models\u001b[39m(max_depths,\n\u001b[32m      2\u001b[39m                      min_samples_split,\n\u001b[32m      3\u001b[39m                      criterion,\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m                      X_train=\u001b[43mX_train\u001b[49m,\n\u001b[32m      5\u001b[39m                      t_train=T_train,\n\u001b[32m      6\u001b[39m                      X_valid=X_valid,\n\u001b[32m      7\u001b[39m                      t_valid=T_valid):\n\u001b[32m      8\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[33;03m    Parameters:\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[33;03m        `max_depths` - A list of values representing the max_depth values to be\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     20\u001b[39m \u001b[33;03m    For that combination of (max_depth, min_samples_split) hyperparameters.\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m     22\u001b[39m     out = {}\n",
      "\u001b[31mNameError\u001b[39m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv(\"./data/clean_data.csv\")\n",
    "X = df\n",
    "T = pd.read_csv(\"./data/cleaned_data_combined_modified.csv\")[\"Label\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, T_train, T_test = train_test_split(X, T, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_valid, T_train, T_valid = train_test_split(X_train, T_train, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Optimal hyperparameters\n",
    "# model = DecisionTreeClassifier()\n",
    "# model.fit(X_train, T_train)\n",
    "\n",
    "def build_all_models(max_depths,\n",
    "                     min_samples_split,\n",
    "                     criterion,\n",
    "                     X_train=X_train,\n",
    "                     t_train=T_train,\n",
    "                     X_valid=X_valid,\n",
    "                     t_valid=T_valid):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        `max_depths` - A list of values representing the max_depth values to be\n",
    "                       try as hyperparameter values\n",
    "        `min_samples_split` - An list of values representing the min_samples_split\n",
    "                       values to try as hyperpareameter values\n",
    "        `criterion` -  A string; either \"entropy\" or \"gini\"\n",
    "\n",
    "    Returns a dictionary, `out`, whose keys are the the hyperparameter choices, and whose values are\n",
    "    the training and validation accuracies (via the `score()` method).\n",
    "    In other words, out[(max_depth, min_samples_split)]['val'] = validation score and\n",
    "                    out[(max_depth, min_samples_split)]['train'] = training score\n",
    "    For that combination of (max_depth, min_samples_split) hyperparameters.\n",
    "    \"\"\"\n",
    "    out = {}\n",
    "\n",
    "    for d in max_depths:\n",
    "        for s in min_samples_split:\n",
    "            out[(d, s)] = {}\n",
    "            # Create a DecisionTreeClassifier based on the given hyperparameters and fit it to the data\n",
    "            tree = DecisionTreeClassifier(criterion=criterion, min_samples_split=s, max_depth=d)\n",
    "            tree.fit(X_train, T_train)\n",
    "            out[(d, s)]['val'] = tree.score(X_valid, t_valid)\n",
    "            out[(d, s)]['train'] = tree.score(X_train, t_train)\n",
    "    return out\n",
    "\n",
    "\n",
    "max_depths = [1, 5, 10, 15, 20, 25, 30, 50, 100]\n",
    "min_samples_split = [2, 4, 8, 16, 32, 64, 128, 256, 512, 1024]\n",
    "\n",
    "res = build_all_models(max_depths=max_depths,min_samples_split=min_samples_split,criterion=\"entropy\",X_train=X_train,t_train=T_train,X_valid=X_valid,t_valid=T_valid) # run build_all_models on all hyperparams\n",
    "optimal=(-1,-1)\n",
    "best_score=0\n",
    "for d, s in res:\n",
    "    if res[(d, s)]['val'] > best_score:\n",
    "        best_score = res[(d, s)]['val']\n",
    "        optimal = (d, s)\n",
    "print(\"Best parameters: {}\".format(optimal))\n",
    "print(\"Best score: {}\".format(best_score))\n",
    "\n",
    "\n",
    "model = DecisionTreeClassifier(criterion=\"entropy\", min_samples_split=optimal[1], max_depth=optimal[0])\n",
    "model.fit(X_train, T_train)\n",
    "print(model.score(X_train, T_train))\n",
    "print(model.score(X_valid, T_valid))\n",
    "print(model.score(X_test, T_test))\n",
    "dot_data = tree.export_graphviz(model)\n",
    "graph = Source(dot_data)\n",
    "# graph.render(\"decision_tree\", format=\"png\", cleanup=True)  # Saves as decision_tree.png\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
